{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMce8muBqXQP"
      },
      "source": [
        "# Tensorflow with GPU\n",
        "\n",
        "This notebook provides an introduction to computing on a [GPU](https://cloud.google.com/gpu) in Colab. In this notebook you will connect to a GPU, and then run some basic TensorFlow operations on both the CPU and a GPU, observing the speedup provided by using the GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM_8ELnJq_wd"
      },
      "source": [
        "## Enabling and testing the GPU\n",
        "\n",
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "- Navigate to Editâ†’Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXnDmXR7RDr2",
        "outputId": "3ea24485-98a9-414e-f5d3-dc9c16efa22a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3fE7KmKRDsH"
      },
      "source": [
        "## Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y04m-jvKRDsJ",
        "outputId": "a75a9b7b-226f-4635-99ff-2288a36e23e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "4.495481800000562\n",
            "GPU (s):\n",
            "0.10259333400063042\n",
            "GPU speedup over CPU: 43x\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer, Dense\n",
        "\n",
        "# Import Sionna\n",
        "try:\n",
        "    import sionna\n",
        "except ImportError as e:\n",
        "    # Install Sionna if package is not already installed\n",
        "    import os\n",
        "    os.system(\"pip install sionna\")\n",
        "    import sionna\n",
        "    \n",
        "from sionna.channel import AWGN\n",
        "from sionna.utils import BinarySource, ebnodb2no, log10, expand_to_rank, insert_dims\n",
        "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
        "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
        "from sionna.mapping import Mapper, Demapper, Constellation\n",
        "from sionna.utils import sim_ber"
      ],
      "metadata": {
        "id": "YtzYMuU0l1wT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters"
      ],
      "metadata": {
        "id": "nI_YqT1EuVqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################\n",
        "# SNR range for evaluation and training [dB]\n",
        "###############################################\n",
        "ebno_db_min = 5.0\n",
        "ebno_db_max = 8.0\n",
        "\n",
        "###############################################\n",
        "# Modulation and coding configuration\n",
        "###############################################\n",
        "num_bits_per_symbol = 6 # Baseline is 64-QAM\n",
        "modulation_order = 2**num_bits_per_symbol\n",
        "coderate = 0.5 # Coderate for the outer code\n",
        "n = 1500 # Codeword length [bit]. Must be a multiple of num_bits_per_symbol\n",
        "num_symbols_per_codeword = n//num_bits_per_symbol # Number of modulated baseband symbols per codeword\n",
        "k = int(n*coderate) # Number of information bits per codeword\n",
        "\n",
        "###############################################\n",
        "# Training configuration\n",
        "###############################################\n",
        "num_training_iterations_conventional = 10000 # Number of training iterations for conventional training\n",
        "# Number of training iterations with RL-based training for the alternating training phase and fine-tuning of the receiver phase\n",
        "num_training_iterations_rl_alt = 7000\n",
        "num_training_iterations_rl_finetuning = 3000\n",
        "training_batch_size = tf.constant(128, tf.int32) # Training batch size\n",
        "rl_perturbation_var = 0.01 # Variance of the perturbation used for RL-based training of the transmitter\n",
        "model_weights_path_conventional_training = \"awgn_autoencoder_weights_conventional_training\" # Filename to save the autoencoder weights once conventional training is done\n",
        "model_weights_path_rl_training = \"awgn_autoencoder_weights_rl_training\" # Filename to save the autoencoder weights once RL-based training is done\n",
        "\n",
        "###############################################\n",
        "# Evaluation configuration\n",
        "###############################################\n",
        "results_filename = \"awgn_autoencoder_results\" # Location to save the results"
      ],
      "metadata": {
        "id": "dUYYmWYlo-eP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Demapper"
      ],
      "metadata": {
        "id": "HCJyLn6BueAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralDemapper(Layer):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self._dense_1 = Dense(128, 'relu')\n",
        "        self._dense_2 = Dense(128, 'relu')\n",
        "        self._dense_3 = Dense(num_bits_per_symbol, None) # The feature correspond to the LLRs for every bits carried by a symbol\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        y,no = inputs\n",
        "        \n",
        "        # Using log10 scale helps with the performance\n",
        "        no_db = log10(no)\n",
        "        \n",
        "        # Stacking the real and imaginary components of the complex received samples\n",
        "        # and the noise variance\n",
        "        no_db = tf.tile(no_db, [1, num_symbols_per_codeword]) # [batch size, num_symbols_per_codeword]\n",
        "        z = tf.stack([tf.math.real(y),\n",
        "                      tf.math.imag(y),\n",
        "                      no_db], axis=2) # [batch size, num_symbols_per_codeword, 3]        \n",
        "        llr = self._dense_1(z)\n",
        "        llr = self._dense_2(llr)\n",
        "        llr = self._dense_3(llr) # [batch size, num_symbols_per_codeword, num_bits_per_symbol]\n",
        "        \n",
        "        return llr"
      ],
      "metadata": {
        "id": "k-gJ9xMhuabn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainable End-to-end System: Conventional Training"
      ],
      "metadata": {
        "id": "Co4znunu15Oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class E2ESystemConventionalTraining(Model):\n",
        "    \n",
        "    def __init__(self, training):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._training = training\n",
        "            \n",
        "        ################\n",
        "        ## Transmitter\n",
        "        ################\n",
        "        self._binary_source = BinarySource()\n",
        "        # To reduce the computational complexity of training, the outer code is not used when training,\n",
        "        # as it is not required\n",
        "        if not self._training:\n",
        "            self._encoder = LDPC5GEncoder(k, n)\n",
        "        # Trainable constellation\n",
        "        constellation = Constellation(\"qam\", num_bits_per_symbol, trainable=True)\n",
        "        self.constellation = constellation\n",
        "        self._mapper = Mapper(constellation=constellation)\n",
        "        \n",
        "        ################\n",
        "        ## Channel\n",
        "        ################\n",
        "        self._channel = AWGN()\n",
        "        \n",
        "        ################\n",
        "        ## Receiver\n",
        "        ################\n",
        "        # We use the previously defined neural network for demapping\n",
        "        self._demapper = NeuralDemapper()\n",
        "        # To reduce the computational complexity of training, the outer code is not used when training,\n",
        "        # as it is not required\n",
        "        if not self._training:\n",
        "            self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n",
        "            \n",
        "        #################\n",
        "        # Loss function\n",
        "        #################\n",
        "        if self._training:\n",
        "            self._bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    \n",
        "    @tf.function(jit_compile=True)\n",
        "    def call(self, batch_size, ebno_db):\n",
        "        \n",
        "        # If `ebno_db` is a scalar, a tensor with shape [batch size] is created as it is what is expected by some layers\n",
        "        if len(ebno_db.shape) == 0:\n",
        "            ebno_db = tf.fill([batch_size], ebno_db)\n",
        "        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n",
        "        no = expand_to_rank(no, 2)\n",
        "        \n",
        "        ################\n",
        "        ## Transmitter\n",
        "        ################\n",
        "        # Outer coding is only performed if not training\n",
        "        if self._training:\n",
        "            c = self._binary_source([batch_size, n])\n",
        "        else:\n",
        "            b = self._binary_source([batch_size, k])\n",
        "            c = self._encoder(b)\n",
        "        # Modulation\n",
        "        x = self._mapper(c) # x [batch size, num_symbols_per_codeword]\n",
        "        \n",
        "        ################\n",
        "        ## Channel\n",
        "        ################\n",
        "        y = self._channel([x, no]) # [batch size, num_symbols_per_codeword]\n",
        "\n",
        "        ################\n",
        "        ## Receiver\n",
        "        ################\n",
        "        llr = self._demapper([y, no])\n",
        "        llr = tf.reshape(llr, [batch_size, n])\n",
        "        # If training, outer decoding is not performed and the BCE is returned\n",
        "        if self._training:\n",
        "            loss = self._bce(c, llr)\n",
        "            return loss\n",
        "        else:\n",
        "            # Outer decoding\n",
        "            b_hat = self._decoder(llr)\n",
        "            return b,b_hat # Ground truth and reconstructed information bits returned for BER/BLER computation"
      ],
      "metadata": {
        "id": "M8Ohytmzupsl"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conventional_training(model):\n",
        "    # Optimizer used to apply gradients\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    \n",
        "    for i in range(num_training_iterations_conventional):\n",
        "        # Sampling a batch of SNRs\n",
        "        ebno_db = tf.random.uniform(shape=[training_batch_size], minval=ebno_db_min, maxval=ebno_db_max)\n",
        "        # Forward pass\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = model(training_batch_size, ebno_db) # The model is assumed to return the BMD rate\n",
        "        # Computing and applying gradients        \n",
        "        weights = model.trainable_weights\n",
        "        grads = tape.gradient(loss, weights)\n",
        "        optimizer.apply_gradients(zip(grads, weights))\n",
        "        # Printing periodically the progress\n",
        "        if i % 100 == 0:\n",
        "            print('Iteration {}/{}  BCE: {:.4f}'.format(i, num_training_iterations_conventional, loss.numpy()), end='\\r')"
      ],
      "metadata": {
        "id": "X9oUttbovc1m"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_weights(model, model_weights_path):\n",
        "    weights = model.get_weights()\n",
        "    with open(model_weights_path, 'wb') as f:\n",
        "        pickle.dump(weights, f)"
      ],
      "metadata": {
        "id": "mDyHH_n_v0FW"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the seed for reproducible trainings\n",
        "tf.random.set_seed(1)\n",
        "# Instantiate and train the end-to-end system\n",
        "model = E2ESystemConventionalTraining(training=True)\n",
        "conventional_training(model)\n",
        "# Save weights\n",
        "save_weights(model, model_weights_path_conventional_training)"
      ],
      "metadata": {
        "id": "eIzNqEvfv3Ym",
        "outputId": "b889a9a0-35aa-469b-9e11-2cba37e068fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainable End-to-end System: RL-based Training\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jW-wiqe_1Noj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class E2ESystemRLTraining(Model):\n",
        "    \n",
        "    def __init__(self, training):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._training = training\n",
        "            \n",
        "        ################\n",
        "        ## Transmitter\n",
        "        ################\n",
        "        self._binary_source = BinarySource()\n",
        "        # To reduce the computational complexity of training, the outer code is not used when training,\n",
        "        # as it is not required\n",
        "        if not self._training:\n",
        "            self._encoder = LDPC5GEncoder(k, n)\n",
        "        # Trainable constellation\n",
        "        constellation = Constellation(\"qam\", num_bits_per_symbol, trainable=True)\n",
        "        self.constellation = constellation\n",
        "        self._mapper = Mapper(constellation=constellation)\n",
        "        \n",
        "        ################\n",
        "        ## Channel\n",
        "        ################\n",
        "        self._channel = AWGN()\n",
        "        \n",
        "        ################\n",
        "        ## Receiver\n",
        "        ################\n",
        "        # We use the previously defined neural network for demapping\n",
        "        self._demapper = NeuralDemapper()\n",
        "        # To reduce the computational complexity of training, the outer code is not used when training,\n",
        "        # as it is not required\n",
        "        if not self._training:\n",
        "            self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n",
        "    \n",
        "    @tf.function(jit_compile=True)\n",
        "    def call(self, batch_size, ebno_db, perturbation_variance=tf.constant(0.0, tf.float32)):\n",
        "        \n",
        "        # If `ebno_db` is a scalar, a tensor with shape [batch size] is created as it is what is expected by some layers\n",
        "        if len(ebno_db.shape) == 0:\n",
        "            ebno_db = tf.fill([batch_size], ebno_db)\n",
        "        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n",
        "        no = expand_to_rank(no, 2)\n",
        "        \n",
        "        ################\n",
        "        ## Transmitter\n",
        "        ################\n",
        "        # Outer coding is only performed if not training\n",
        "        if self._training:\n",
        "            c = self._binary_source([batch_size, n])\n",
        "        else:\n",
        "            b = self._binary_source([batch_size, k])\n",
        "            c = self._encoder(b)\n",
        "        # Modulation\n",
        "        x = self._mapper(c) # x [batch size, num_symbols_per_codeword]\n",
        "    \n",
        "        # Adding perturbation\n",
        "        # If ``perturbation_variance`` is 0, then the added perturbation is null\n",
        "        epsilon_r = tf.random.normal(tf.shape(x))*tf.sqrt(0.5*perturbation_variance)\n",
        "        epsilon_i = tf.random.normal(tf.shape(x))*tf.sqrt(0.5*perturbation_variance)\n",
        "        epsilon = tf.complex(epsilon_r, epsilon_i) # [batch size, num_symbols_per_codeword]\n",
        "        x_p = x + epsilon # [batch size, num_symbols_per_codeword]\n",
        "        \n",
        "        ################\n",
        "        ## Channel\n",
        "        ################\n",
        "        y = self._channel([x_p, no]) # [batch size, num_symbols_per_codeword]\n",
        "        y = tf.stop_gradient(y) # Stop gradient here\n",
        "\n",
        "        ################\n",
        "        ## Receiver\n",
        "        ################\n",
        "        llr = self._demapper([y, no]) \n",
        "\n",
        "        # If training, outer decoding is not performed\n",
        "        if self._training:\n",
        "            # Average BCE for each baseband symbol and each batch example\n",
        "            c = tf.reshape(c, [-1, num_symbols_per_codeword, num_bits_per_symbol])\n",
        "            bce = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(c, llr), axis=2) # Avergare over the bits mapped to a same baseband symbol\n",
        "            # The RX loss is the usual average BCE\n",
        "            rx_loss = tf.reduce_mean(bce)\n",
        "            # From the TX side, the BCE is seen as a feedback from the RX through which backpropagation is not possible\n",
        "            bce = tf.stop_gradient(bce) # [batch size, num_symbols_per_codeword]\n",
        "            x_p = tf.stop_gradient(x_p)\n",
        "            p = x_p-x # [batch size, num_symbols_per_codeword] Gradient is backpropagated through `x`\n",
        "            tx_loss = tf.square(tf.math.real(p)) + tf.square(tf.math.imag(p)) # [batch size, num_symbols_per_codeword]\n",
        "            tx_loss = -bce*tx_loss/rl_perturbation_var # [batch size, num_symbols_per_codeword]\n",
        "            tx_loss = tf.reduce_mean(tx_loss)\n",
        "            return tx_loss, rx_loss\n",
        "        else:\n",
        "            llr = tf.reshape(llr, [-1, n]) # Reshape as expected by the outer decoder\n",
        "            b_hat = self._decoder(llr)\n",
        "            return b,b_hat"
      ],
      "metadata": {
        "id": "vRIwHbZSv_mW"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rl_based_training(model):\n",
        "    # Optimizers used to apply gradients\n",
        "    optimizer_tx = tf.keras.optimizers.Adam() # For training the transmitter\n",
        "    optimizer_rx = tf.keras.optimizers.Adam() # For training the receiver\n",
        "\n",
        "    # Function that implements one transmitter training iteration using RL.\n",
        "    def train_tx():\n",
        "        # Sampling a batch of SNRs\n",
        "        ebno_db = tf.random.uniform(shape=[training_batch_size], minval=ebno_db_min, maxval=ebno_db_max)\n",
        "        # Forward pass\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Keep only the TX loss\n",
        "            tx_loss, _ = model(training_batch_size, ebno_db,\n",
        "                               tf.constant(rl_perturbation_var, tf.float32)) # Perturbation are added to enable RL exploration\n",
        "        ## Computing and applying gradients\n",
        "        weights = model.trainable_weights\n",
        "        grads = tape.gradient(tx_loss, weights)\n",
        "        optimizer_tx.apply_gradients(zip(grads, weights))\n",
        "    \n",
        "    # Function that implements one receiver training iteration\n",
        "    def train_rx():\n",
        "        # Sampling a batch of SNRs\n",
        "        ebno_db = tf.random.uniform(shape=[training_batch_size], minval=ebno_db_min, maxval=ebno_db_max)\n",
        "        # Forward pass\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Keep only the RX loss\n",
        "            _, rx_loss = model(training_batch_size, ebno_db) # No perturbation is added\n",
        "        ## Computing and applying gradients\n",
        "        weights = model.trainable_weights\n",
        "        grads = tape.gradient(rx_loss, weights)\n",
        "        optimizer_rx.apply_gradients(zip(grads, weights))\n",
        "        # The RX loss is returned to print the progress\n",
        "        return rx_loss\n",
        "    \n",
        "    # Training loop.\n",
        "    for i in range(num_training_iterations_rl_alt):\n",
        "        # 10 steps of receiver training are performed to keep it ahead of the transmitter\n",
        "        # as it is used for computing the losses when training the transmitter\n",
        "        for _ in range(10):\n",
        "            rx_loss = train_rx()\n",
        "        # One step of transmitter training\n",
        "        train_tx()             \n",
        "        # Printing periodically the progress\n",
        "        if i % 100 == 0:\n",
        "            print('Iteration {}/{}  BCE {:.4f}'.format(i, num_training_iterations_rl_alt, rx_loss.numpy()), end='\\r')\n",
        "    print() # Line break\n",
        "    \n",
        "    # Once alternating training is done, the receiver is fine-tuned.\n",
        "    print('Receiver fine-tuning... ')\n",
        "    for i in range(num_training_iterations_rl_finetuning):\n",
        "        rx_loss = train_rx()\n",
        "        if i % 100 == 0:\n",
        "            print('Iteration {}/{}  BCE {:.4f}'.format(i, num_training_iterations_rl_finetuning, rx_loss.numpy()), end='\\r')"
      ],
      "metadata": {
        "id": "J1owRYle1Q6i"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "instance of the model defined previously is instantiated and trained."
      ],
      "metadata": {
        "id": "YdNsvFR63Hpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the seed for reproducible trainings\n",
        "tf.random.set_seed(1)\n",
        "# Instantiate and train the end-to-end system\n",
        "model = E2ESystemRLTraining(training=True)\n",
        "rl_based_training(model)\n",
        "# Save weights\n",
        "save_weights(model, model_weights_path_rl_training)\n"
      ],
      "metadata": {
        "id": "gVlJYShX1gHN",
        "outputId": "5450e79a-f54a-4980-c8c1-57665b23089a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QD24O4Xk3A1f"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "TensorFlow with GPU",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}